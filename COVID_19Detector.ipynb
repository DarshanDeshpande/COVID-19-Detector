{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PmIPtB5lh0Nd",
    "outputId": "16593af5-9c3c-4f72-fddf-e70954bd0e62"
   },
   "outputs": [],
   "source": [
    "# %tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2,glob,os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m2h1gIDUhk1o"
   },
   "outputs": [],
   "source": [
    "class_list = ['Normal','Corona','BacterialPneumonia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nABuD5tRXUtW"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(glob.glob('/content/drive/My Drive/CoronaVirusData/TrainData/*.tfrecord'),num_parallel_reads=20)\n",
    "val_dataset = tf.data.TFRecordDataset('/content/drive/My Drive/CoronaVirusData/Validation.tfrecord')\n",
    "test_dataset = tf.data.TFRecordDataset('/content/drive/My Drive/CoronaVirusData/Test.tfrecord')\n",
    "\n",
    "# Create a dictionary describing the features.\n",
    "image_feature_description = {\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64)\n",
    "}\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "  features = tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "  image_raw = tf.image.decode_jpeg(features['image_raw'],channels=1)\n",
    "  image_raw = tf.cast(image_raw , tf.float32) * (1. / 255)\n",
    "  image_raw = tf.image.resize(image_raw,(300,400))\n",
    "\n",
    "  label = features['label']\n",
    "\n",
    "  return image_raw,label\n",
    "\n",
    "train_dataset = train_dataset.map(_parse_image_function)\n",
    "val_dataset = val_dataset.map(_parse_image_function)\n",
    "test_dataset = test_dataset.map(_parse_image_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rmut-CmiC4ot"
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.repeat().shuffle(600).batch(16).prefetch(8)\n",
    "val_dataset = val_dataset.repeat().shuffle(10).batch(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "yuKI5ui1eUA0",
    "outputId": "e9f35731-ac63-4ee2-95f9-3341cf68b89c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.7227138643067846, 0.8781362007168458, 2.094017094017094}\n"
     ]
    }
   ],
   "source": [
    "# manually finding out the class weights to be assigned since I dont know any other way for tensors\n",
    "\n",
    "samples = {(339+279+54+63)/(3*339),(339+279+54+63)/(3*279),(339+279+54+63)/(3*(54+63))}\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FL9wKiIiaeRt"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,Conv2D,SeparableConv2D,Dropout,MaxPool2D,MaxPooling2D,GlobalMaxPooling2D,BatchNormalization,Flatten,Dense\n",
    "\n",
    "def create_model(shape=(300,400,1)):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(Conv2D(32,(5,5),input_shape=shape))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(16,(3,3)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(8,(2,2)))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(BatchNormalization())    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(len(class_list),activation='softmax'))          \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "colab_type": "code",
    "id": "Y1MPrVEkfr3t",
    "outputId": "c8f19250-6c59-45f9-d980-aa288b94780d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 296, 396, 32)      832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 148, 198, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 148, 198, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 146, 196, 16)      4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 73, 98, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 73, 98, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 72, 97, 8)         520       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 36, 48, 8)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 36, 48, 8)         32        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 13824)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                221200    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 227,923\n",
      "Trainable params: 227,811\n",
      "Non-trainable params: 112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oU4Wc6frf3JM"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer=optimizer,metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aD7vd1x6PODk"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3nVtAx3sfSB2"
   },
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=2,verbose=1)\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('Checkpoint1.h5',save_best_only=True,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 742
    },
    "colab_type": "code",
    "id": "fPaEuXZYgCAj",
    "outputId": "626d1278-b88e-4552-8163-d2c76619cb99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 45 steps, validate for 15 steps\n",
      "Epoch 1/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.5003 - sparse_categorical_accuracy: 0.8381\n",
      "Epoch 00001: val_loss improved from 0.43569 to 0.38108, saving model to Checkpoint1.h5\n",
      "45/45 [==============================] - 13s 298ms/step - loss: 0.4994 - sparse_categorical_accuracy: 0.8375 - val_loss: 0.3811 - val_sparse_categorical_accuracy: 0.9600\n",
      "Epoch 2/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.4747 - sparse_categorical_accuracy: 0.8210\n",
      "Epoch 00002: val_loss did not improve from 0.38108\n",
      "45/45 [==============================] - 7s 150ms/step - loss: 0.4740 - sparse_categorical_accuracy: 0.8236 - val_loss: 0.6113 - val_sparse_categorical_accuracy: 0.7733\n",
      "Epoch 3/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.4515 - sparse_categorical_accuracy: 0.8253\n",
      "Epoch 00003: val_loss improved from 0.38108 to 0.37149, saving model to Checkpoint1.h5\n",
      "45/45 [==============================] - 7s 159ms/step - loss: 0.4530 - sparse_categorical_accuracy: 0.8250 - val_loss: 0.3715 - val_sparse_categorical_accuracy: 0.9067\n",
      "Epoch 4/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.4879 - sparse_categorical_accuracy: 0.8253\n",
      "Epoch 00004: val_loss improved from 0.37149 to 0.27374, saving model to Checkpoint1.h5\n",
      "45/45 [==============================] - 7s 154ms/step - loss: 0.4832 - sparse_categorical_accuracy: 0.8292 - val_loss: 0.2737 - val_sparse_categorical_accuracy: 0.9600\n",
      "Epoch 5/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.4324 - sparse_categorical_accuracy: 0.8580\n",
      "Epoch 00005: val_loss did not improve from 0.27374\n",
      "45/45 [==============================] - 7s 151ms/step - loss: 0.4266 - sparse_categorical_accuracy: 0.8597 - val_loss: 0.4285 - val_sparse_categorical_accuracy: 0.8800\n",
      "Epoch 6/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.4711 - sparse_categorical_accuracy: 0.8125\n",
      "Epoch 00006: val_loss improved from 0.27374 to 0.24821, saving model to Checkpoint1.h5\n",
      "45/45 [==============================] - 7s 155ms/step - loss: 0.4674 - sparse_categorical_accuracy: 0.8139 - val_loss: 0.2482 - val_sparse_categorical_accuracy: 0.9733\n",
      "Epoch 7/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.4608 - sparse_categorical_accuracy: 0.8338\n",
      "Epoch 00007: val_loss improved from 0.24821 to 0.24169, saving model to Checkpoint1.h5\n",
      "45/45 [==============================] - 7s 155ms/step - loss: 0.4619 - sparse_categorical_accuracy: 0.8319 - val_loss: 0.2417 - val_sparse_categorical_accuracy: 0.9467\n",
      "Epoch 8/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.4584 - sparse_categorical_accuracy: 0.8423\n",
      "Epoch 00008: val_loss did not improve from 0.24169\n",
      "45/45 [==============================] - 7s 151ms/step - loss: 0.4587 - sparse_categorical_accuracy: 0.8403 - val_loss: 0.3321 - val_sparse_categorical_accuracy: 0.8933\n",
      "Epoch 9/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.4376 - sparse_categorical_accuracy: 0.8438\n",
      "Epoch 00009: val_loss improved from 0.24169 to 0.22681, saving model to Checkpoint1.h5\n",
      "45/45 [==============================] - 7s 156ms/step - loss: 0.4361 - sparse_categorical_accuracy: 0.8444 - val_loss: 0.2268 - val_sparse_categorical_accuracy: 0.9867\n",
      "Epoch 10/10\n",
      "44/45 [============================>.] - ETA: 0s - loss: 0.4421 - sparse_categorical_accuracy: 0.8224\n",
      "Epoch 00010: val_loss improved from 0.22681 to 0.19976, saving model to Checkpoint1.h5\n",
      "45/45 [==============================] - 7s 154ms/step - loss: 0.4428 - sparse_categorical_accuracy: 0.8222 - val_loss: 0.1998 - val_sparse_categorical_accuracy: 0.9467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc0f2c966d8>"
      ]
     },
     "execution_count": 107,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset,validation_data=val_dataset,shuffle=True,epochs=10,class_weight=samples,steps_per_epoch=(672+63)//16,validation_steps=75//5,callbacks=[early_stopping,model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BKHVQhLQVCKu"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('Checkpoint1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zaOr-7WAVI7E",
    "outputId": "79c0d12d-ae35-47f5-f55b-f2af0afa5348"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2]"
      ]
     },
     "execution_count": 108,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds=model.predict(test_dataset.batch(15),batch_size=None)\n",
    "preds = [np.argmax(i) for i in preds]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "l7WwibUxVfGN",
    "outputId": "44eb4365-6302-4c99-e680-bcb54367c294"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2]"
      ]
     },
     "execution_count": 109,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = []\n",
    "for i,j in test_dataset:\n",
    "  predictions.append(j.numpy())\n",
    "predictions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bm85rupjdQ00",
    "outputId": "2914e69c-3a81-4f51-dffa-1ca04f90cc42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for i,j in zip(preds,predictions):\n",
    "  if i==j:\n",
    "    count+=1\n",
    "print(count/len(preds))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oZ1KBuZVdat1"
   },
   "outputs": [],
   "source": [
    "model.save('/content/drive/My Drive/CoronaVirusData/COVID-19-Detector.h5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "COVID-19Detector.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
